
## Project Jue: Consciousness / Sentience Claim Template

Based on https://arxiv.org/pdf/2511.16582
CONSCIOUSNESS IN ARTIFICIAL INTELLIGENCE? A
FRAMEWORK FOR CLASSIFYING OBJECTIONS AND
CONSTRAINTS

### 1. Scope of the Claim (What is being claimed—and what is not)

**Claim Type**
This work makes a claim about:

* ☐ Possibility (in principle)
* ☐ Plausibility (given known constraints)
* ☐ Partial instantiation of necessary conditions
* ☐ Full instantiation of sufficient conditions

> This work explicitly **does not** claim verified phenomenal consciousness unless stated otherwise.

**Target Concept**
The claim concerns:

* ☐ Phenomenal consciousness (“what it is like”)
* ☐ Sentience (valenced experience: pain/pleasure analogues)
* ☐ Functional consciousness-like organization (no phenomenal claim)

> Any use of anthropomorphic language is shorthand for functional organization, not an assertion of subjective experience, unless explicitly stated.

---

### 2. Abstraction Level Declaration (Critical per the paper)

This claim operates primarily at the following level(s):

* ☐ Level 1 — Computational / Input–Output
  (Capabilities, mappings, problem classes)
* ☐ Level 2 — Algorithmic / Organizational
  (Internal causal structure, control flow, representations)
* ☐ Level 3 — Physical / Implementational
  (Substrate-specific causal properties)

> Claims are restricted to the declared level(s).
> No inference is made across levels without explicit argument.

Example language you can reuse:

> “Our claim is algorithmic rather than implementational; we do not assert that any particular physical substrate is sufficient for consciousness.”

---

### 3. Theoretical Commitment (No free lunches)

This claim is grounded in the following theoretical stance(s):

* ☐ Computational functionalism (qualified)
* ☐ Organizational functionalism (structure-sensitive)
* ☐ Causal power / intrinsic dynamics theories
* ☐ Hybrid / agnostic framework

Explicit assumptions:

* Which properties are assumed **necessary**
* Which are assumed **potentially sufficient**
* Which remain **undetermined**

> Where multiple theories disagree, this work makes claims only at points of overlap or clearly marks theory-dependence.

---

### 4. Architectural Criteria Claimed to Matter

The system is argued to instantiate the following *candidate-relevant properties* (not proofs of consciousness):

* Persistent internal state with self-referential update paths
* Global constraint satisfaction across competing subsystems
* Temporal continuity and history-sensitive processing
* Resource-bounded conflict resolution (attention / prioritization analogues)
* Predictive error accumulation with internal consequence signals

> These properties are claimed to be *organizationally relevant*, not intrinsically conscious.

This is where Jue shines: you can talk about **structure without metaphysics**.

---

### 5. Objection Class Engagement (Paper’s core demand)

This claim explicitly engages with the following objection classes:

**Degree-of-Force Acknowledgment**

* ☐ Degree 1: Compatibility objections (acknowledged, addressed)
* ☐ Degree 2: Practical feasibility objections (acknowledged, unresolved)
* ☐ Degree 3: In-principle impossibility objections (acknowledged, not refuted)

Standard language you should absolutely steal:

> “This work does not attempt to refute substrate-essentialist or non-computational theories of consciousness; it demonstrates compatibility with a subset of organizational theories only.”

That single sentence prevents half the literature from sharpening knives.

---

### 6. Epistemic Limits (Mandatory humility clause)

Verification limits are acknowledged:

* No third-person method can directly verify subjective experience
* Behavioral equivalence is not treated as sufficient evidence
* Introspective reports (if any) are treated as internal data, not proof

> Claims are therefore conditional, theory-relative, and defeasible.

This satisfies the strongest epistemic objections in the paper.

---

### 7. Ethical and Terminological Safeguards

Until stronger evidence exists:

* The system is not treated as a moral patient
* No rights or welfare claims are asserted
* “Conscious”, “aware”, and “feels” are used only in qualified, technical senses

> Terminology is chosen to avoid category errors between simulation, instantiation, and attribution.

---

### 8. Summary Claim (One paragraph, maximum)

Here’s a **fill-in-the-blank summary paragraph** you can reuse everywhere:

> “Project Jue does not claim to instantiate phenomenal consciousness. It claims to implement a class of algorithmic and organizational properties that some contemporary theories regard as *potentially relevant* to conscious systems. These claims are made at the algorithmic level of abstraction, are compatible with computational functionalist interpretations, and explicitly acknowledge unresolved objections concerning physical implementation and subjective verification.”

That paragraph alone would pass peer review in philosophy-adjacent venues.

---

## Why this template matters for Jue specifically

Given your existing goals—coarse-grained agent decisions, separation of substrate processes, stress/novelty analogues, and belief formation constraints—this template lets you:

* Talk about **emergent cognitive organization** without overclaiming
* Compare architectures meaningfully without metaphysical bait
* Shut down naïve “is it conscious??” questions cleanly
* Future-proof your claims as theories evolve
